{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoRFmYqtoz8X"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install openai\n",
        "!pip install diffusers\n",
        "!pip install transformers scipy ftfy accelerate\n",
        "!pip install git+https://github.com/huggingface/diffusers\n",
        "!pip install safetensors\n",
        "!pip install langchain\n",
        "!pip3 install python-dotenv\n",
        "!pip install google-search-results\n",
        "!pip install Pillow\n",
        "%pip install stability-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3RKmLIj2BOh"
      },
      "outputs": [],
      "source": [
        "pip install invisible_watermark safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw0WpUzpywa4",
        "outputId": "92c02978-0e47-466b-db27-c2f385ca4c69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "# Import necessary libraries\n",
        "import openai\n",
        "from diffusers import DiffusionPipeline, StableDiffusionXLPipeline\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import torch\n",
        "import urllib\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import time\n",
        "from diffusers import DiffusionPipeline, StableDiffusionXLPipeline\n",
        "import io\n",
        "import warnings\n",
        "from stability_sdk import client\n",
        "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
        "import IPython.display as display\n",
        "\n",
        "# Set API keys and configurations\n",
        "export OPENAI_API_KEY='your-openai-api-key'\n",
        "export SERPAPI_API_KEY='your-serpapi-api-key'\n",
        "export STABILITY_HOST='grpc.stability.ai:443'\n",
        "export STABILITY_KEY='your-stability-key'\n",
        "\n",
        "# Configure Streamlit app\n",
        "st.set_page_config(\n",
        "    page_title=\"AI Blog Generator\",\n",
        "    page_icon=\":pushpin:\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Function to generate images using different engines\n",
        "def generate_images(prompt, select_model):\n",
        "\n",
        "    if select_model == \"segmind/SSD-1B\":\n",
        "        device = \"cuda\"\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\"segmind/SSD-1B\", torch_dtype=torch.float16,\n",
        "                                                         use_safetensors=True, variant=\"fp16\")\n",
        "        pipe.to(\"cuda\")\n",
        "        neg_prompt = \"ugly, blurry, poor quality\"\n",
        "        return pipe(prompt=prompt, negative_prompt=neg_prompt).images[0]\n",
        "\n",
        "    elif select_model == \"stable-diffusion-xl-1024-v1-0\":\n",
        "        stability_api = client.StabilityInference(\n",
        "            key=os.environ['STABILITY_KEY'],\n",
        "            verbose=True,\n",
        "            engine=\"stable-diffusion-xl-1024-v1-0\",\n",
        "        )\n",
        "        answers = stability_api.generate(\n",
        "            prompt=prompt,\n",
        "            seed=4254978046, steps=50, cfg_scale=8.0, samples=1,\n",
        "            sampler=generation.SAMPLER_K_DPMPP_2M\n",
        "        )\n",
        "        for resp in answers:\n",
        "            for artifact in resp.artifacts:\n",
        "                if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "                    img = Image.open(io.BytesIO(artifact.binary))\n",
        "                    return img\n",
        "\n",
        "\n",
        "# Streamlit UI styling\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "        .sidebar .sidebar-content {\n",
        "            background-color: #31bd56;\n",
        "            color: #F1D700;\n",
        "        }\n",
        "        .sidebar .stButton {\n",
        "            background-color: #F7D700;\n",
        "            color: #233142;\n",
        "        }\n",
        "        .sidebar .stSelectbox {\n",
        "            background-color: #FFD700;\n",
        "            color: #2D3742;\n",
        "        }\n",
        "        .widget-title {\n",
        "            color: #2D3142;\n",
        "        }\n",
        "        .main .wrapper {\n",
        "            background-color: #F4F4F4;\n",
        "        }\n",
        "        .stMarkdown {\n",
        "            color: #d1d6e8;\n",
        "            font-size: 18px;\n",
        "        }\n",
        "        .stHeader {\n",
        "            color: #2A3142;\n",
        "            font-size: 30px;\n",
        "        }\n",
        "        .stSubheader {\n",
        "            color: #2D3142;\n",
        "            font-size: 24px;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "# Streamlit App\n",
        "\n",
        "with st.sidebar:\n",
        "    st.title(\"AI Blog Generator\")\n",
        "    num_of_keywords = st.text_input(\"Enter the number of Keywords:\")\n",
        "    topic = st.text_input(\"Enter the topic title:\")\n",
        "    select_engine = st.selectbox(\"Select Model\", [\"segmind/SSD-1B\", \"stable-diffusion-xl-1024-v1-0\"])\n",
        "    button = st.button(\"Generate Blog\")\n",
        "\n",
        "if button:\n",
        "    # Keywords\n",
        "    prompt_template_name = PromptTemplate(\n",
        "        input_variables=['Topic', 'NumOfKeywords'],\n",
        "        template=(\n",
        "            \"\"\"Provide the most common {NumOfKeywords} keywords related to the topic \"{Topic}\".\n",
        "              Please just list the keywords in point form as follows:\n",
        "              1.\n",
        "              2.\n",
        "              3.\n",
        "            \"\"\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    p = prompt_template_name.format(Topic=topic, NumOfKeywords=num_of_keywords)\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0.5)\n",
        "\n",
        "    # Initialize agent\n",
        "    tools = load_tools([\"serpapi\", \"llm-math\", \"requests_all\"], llm=llm)\n",
        "    agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True, handle_parsing_errors=True)\n",
        "    result = agent.run(p)\n",
        "    splited_result = result.split(\"\\n\")\n",
        "    st.header(f\"Blog related to {topic}\")\n",
        "    with st.sidebar:\n",
        "         st.markdown(f\"\"\"\n",
        "                ##Keywords:\n",
        "{result}\n",
        "                \"\"\")\n",
        "\n",
        "    for i, Keyword in enumerate(splited_result):\n",
        "        if i != 1:\n",
        "            st.subheader(f\"Keyword: {Keyword}\")\n",
        "            prompt_template_name = PromptTemplate(\n",
        "                input_variables=['keyword', 'Topic'],\n",
        "                template=(\n",
        "                    \"\"\"Generate a paragraph of up to 80 words about {keyword} in the context of {Topic}.\"\"\"\n",
        "                )\n",
        "            )\n",
        "            time.sleep(20)\n",
        "            p = prompt_template_name.format(keyword=Keyword, Topic=topic)\n",
        "            paragraph_result = agent.run(p)\n",
        "            st.markdown(f'<div style=\"margin-top: 10px; margin-bottom: 10px; font-size: 20px;text-align: justify;\">{paragraph_result}</div>', unsafe_allow_html=True)\n",
        "\n",
        "            prompt_template_name = PromptTemplate(\n",
        "                input_variables=['paragraph_result'],\n",
        "                template=(\n",
        "                    \"\"\"Generate the detailed image prompt that conveying the following text:\n",
        "\n",
        "                      {paragraph_result}\n",
        "\n",
        "                      Follow this format: [type of art], [subject or topic], [action or activity], [aesthetic details, lighting, and styles], [colors], [--ar aspect ratio]\n",
        "                      \"\"\"\n",
        "                )\n",
        "            )\n",
        "            time.sleep(10)\n",
        "            p = prompt_template_name.format(paragraph_result=paragraph_result)\n",
        "            agent_for_image_prompt_1 = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, handle_parsing_errors=True)\n",
        "            image_prompt = agent_for_image_prompt_1.run(p)\n",
        "            image = generate_images(prompt=image_prompt, select_engine=select_engine)\n",
        "            st.image(image, caption=f\"Generated Image for {Keyword}\", use_column_width=True)\n",
        "            with st.expander(\"See prompt\"):\n",
        "                 st.markdown(f'<div style=\"margin-top: 10px; margin-bottom: 10px; font-size: 16px;text-align: justify;\">{image_prompt}</div>', unsafe_allow_html=True)\n",
        "\n",
        "        else:\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.subheader(f\"Keyword: {Keyword}\")\n",
        "                prompt_template_name = PromptTemplate(\n",
        "                    input_variables=['keyword', 'Topic'],\n",
        "                    template=(\n",
        "                        \"\"\"Generate a paragraph of up to 100 words about {keyword} in the context of {Topic}.\"\"\"\n",
        "                    )\n",
        "                )\n",
        "                time.sleep(10)\n",
        "                p = prompt_template_name.format(keyword=Keyword, Topic=topic)\n",
        "                paragraph_result = agent.run(p)\n",
        "                st.markdown(f'<div style=\"margin-top: 10px; margin-bottom: 10px; font-size: 18px; text-align: justify;\">{paragraph_result}</div>', unsafe_allow_html=True)\n",
        "\n",
        "            with col2:\n",
        "                prompt_template_name = PromptTemplate(\n",
        "                    input_variables=['paragraph_result'],\n",
        "                    template=(\n",
        "                        \"\"\"Generate the detailed image prompt that conveying the following text:\n",
        "\n",
        "                          {paragraph_result}\n",
        "\n",
        "                          Follow this format: [type of art], [subject or topic], [action or activity], [aesthetic details, lighting, and styles], [colors], [--ar aspect ratio]\n",
        "                          \"\"\"\n",
        "                    )\n",
        "                )\n",
        "                time.sleep(10)\n",
        "                p = prompt_template_name.format(paragraph_result=paragraph_result)\n",
        "                agent_for_image_prompt_2 = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, handle_parsing_errors=True)\n",
        "                image_prompt = agent_for_image_prompt_2.run(p)\n",
        "                image = generate_images(prompt=image_prompt, select_engine=select_engine)\n",
        "                st.image(image, caption=f\"Generated Image for {Keyword}\", use_column_width=True)\n",
        "                with st.expander(\"See prompt\"):\n",
        "                     st.markdown(f'<div style=\"margin-top: 10px; margin-bottom: 10px; font-size: 16px;text-align: justify;\">{image_prompt}</div>', unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxRn8H1sy5ex",
        "outputId": "c0c2c859-a1dd-4c98-d873-62f2164acd6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 3.102s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "bbpkkI3P5Pea"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDaZhSXk5CXs",
        "outputId": "ed63b3d2-72a8-4370-9d7a-0d52c11f9d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.123.190.41\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JMIoWuN5wg1",
        "outputId": "7d4bd906-655e-4a31-bf39-3fd8e4e40602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.72s\n",
            "your url is: https://neat-mugs-cheer.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhwruCJSqOQR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
